{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covariate Shift",
      "provenance": [],
      "authorship_tag": "ABX9TyPh4IWFZ4mMgGhr+7rrxgGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lu-David/CovariateShift/blob/main/Covariate_Shift.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python implementation of 2014 Liu Paper\n",
        "\n",
        "https://proceedings.neurips.cc/paper/2014/file/d67d8ab4f4c10bf22aa353e27879133c-Paper.pdf"
      ],
      "metadata": {
        "id": "_2PBOjKyuBb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "Problem: sample selection bias"
      ],
      "metadata": {
        "id": "jzXvJ6aDWrte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification"
      ],
      "metadata": {
        "id": "Wpc54G11wtVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "folder_path = '/content' # TODO Upload data files and / or specify path\n",
        "\n",
        "x_1 = scipy.io.loadmat(os.path.join(folder_path, 'x_1.mat'))['x_1']\n",
        "x_2 = scipy.io.loadmat(os.path.join(folder_path, 'x_2.mat'))['x_2']\n",
        "y_1 = np.transpose(scipy.io.loadmat(os.path.join(folder_path, 'y_1.mat'))['y_1'])\n",
        "y_2 = np.transpose(scipy.io.loadmat(os.path.join(folder_path, 'y_2.mat'))['y_2'])"
      ],
      "metadata": {
        "id": "S6gJmDSxtt81"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu_s = [6, 6] # source mean \n",
        "var_s = [[3, -2], [-2, 3]] # source variance\n",
        "mu_t = [7, 7] # target mean\n",
        "var_t = [[3, 2], [2, 3]] # target variance"
      ],
      "metadata": {
        "id": "QDH0YmX-0qlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Our approach, in contrast, obtains an estimate for\n",
        "each given target distribution that is robust to all the conditional label distributions matching source\n",
        "statistics. While having an exact or well-estimated target distribution a priori may not be possible\n",
        "for some applications, large amounts of unlabeled data enable this in many batch learning settings.\n",
        "```\n",
        "\n",
        "**Question:** How would you determine the source / target mean / variance in a real world setting? The values that I've set above don't seem to match the values loaded from the matlab data objects. \n"
      ],
      "metadata": {
        "id": "_akzI3tedfMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "DFAqFWgunKyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#\n",
        "#\n",
        "# r_ts : ratio of target / source density distribution for importance weighting method \n",
        "def binaryRobustTrain(X_s, y_s, r_st, r_ts, lamb = 0.001, lr = 1, max_itr = 10000, min_gradient = 0.0001):\n",
        "  n_row, n_col = X_s.shape\n",
        "\n",
        "  F = np.concatenate((np.ones((n_row, 1)), X_s), axis=1) \n",
        "  F_g = F * np.tile(r_ts, n_col + 1)\n",
        "\n",
        "  P = np.zeros((n_row, 1)) \n",
        "  S_g = np.ones((n_col + 1, 1)) * 1e-8\n",
        "\n",
        "  t = 1\n",
        "  theta = np.ones((n_col + 1, 1)) \n",
        "  l_0 = 0\n",
        "  l_1 = (1 + (1 + (4 * l_0 ** 2)) ** 0.5) / 2\n",
        "  delta_1 = 0\n",
        "\n",
        "  while True:\n",
        "    t = t + 1\n",
        "    decay = np.sqrt(1000 / (1000 + t))\n",
        "\n",
        "    l_2 = (1 + (1 + (4 * l_1 ** 2)) ** 0.5) / 2\n",
        "    l_3 = (1 - l_1) / l_2\n",
        "\n",
        "    # TODO: Vectorize? \n",
        "    for i in range(n_row):\n",
        "      W = r_st[i]\n",
        "      temp =  (np.dot(np.transpose(theta), np.transpose(F[i, :])) * y_s[i] * W)[0]      \n",
        "      temp_max = max(temp, -1 * temp)  # multiplied by negative one because Y is -1, 1 instead of 0, 1\n",
        "      temp_min = min(temp, -1 * temp)\n",
        "      P[i] = np.exp(temp - temp_max - np.log(1 + np.exp(temp_min - temp_max))) # Question: np.exp(temp) refers to Theorem 2, but what does temp_max - np.log(everything else) do? Is this some sort of correction term? \n",
        "\n",
        "    # G : Gradient which is the logloss gradient calculated as P \n",
        "    G = np.transpose(np.dot(np.transpose(P * y_s), F_g)) - np.transpose(np.dot(np.transpose(y_s), F_g)) + 2 * lamb * theta\n",
        "    if np.linalg.norm(G) < min_gradient:\n",
        "      print('Optimization stops by reaching minimum gradient.')\n",
        "      break\n",
        "\n",
        "    S_g = S_g + G ** 2\n",
        "    delta_2 = theta - np.dot(decay, lr) * G / np.sqrt(S_g) \n",
        "    theta = np.dot((1 - l_3), delta_2) + np.dot(l_3, delta_1)\n",
        "    delta_1 = delta_2\n",
        "    l_1 = l_2\n",
        "\n",
        "    if t > max_itr:\n",
        "      print(\"Optimizination stops by reaching maximum iteration\")\n",
        "      break\n",
        "  return theta"
      ],
      "metadata": {
        "id": "iSTQ7Wyk0q49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "16-dcKHieZeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust learning\n",
        "\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "mvn_s = multivariate_normal(mu_s, var_s)\n",
        "mvn_t = multivariate_normal(mu_t, var_t)\n",
        "\n",
        "d_s = mvn_s.pdf(x_1)\n",
        "d_t = mvn_t.pdf(x_1)"
      ],
      "metadata": {
        "id": "21mGJZQQYjoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust Learning\n",
        "theta_1 = binaryRobustTrain(x_1, y_1, d_s / d_t, np.ones((x_1.shape[0], 1)))\n",
        "print(\"Weights\", theta_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIOqqxGmdjzw",
        "outputId": "b874c9e9-2e41-47df-a126-6af40543c7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizination stops by reaching maximum iteration\n",
            "Weights [[11.91705313]\n",
            " [-1.00605443]\n",
            " [-1.0069282 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "theta_2 = binaryRobustTrain(x_1, y_1, np.ones((x_1.shape[0], 1)), np.ones((x_1.shape[0], 1)))\n",
        "print(\"Weights\", theta_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1dDLQsdGD8j",
        "outputId": "aa6587e2-0341-4a90-cf8b-d3783bc8234b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization stops by reaching minimum gradient.\n",
            "Weights [[12.35379291]\n",
            " [-1.04099695]\n",
            " [-1.0359673 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importance Weighting\n",
        "r_ts = d_t / d_s\n",
        "theta_3 = binaryRobustTrain(x_1, y_1, np.ones((x_1.shape[0], 1)), r_ts.reshape(r_ts.shape[0], 1))\n",
        "print(\"Weights\", theta_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAggbFoMGZhH",
        "outputId": "baa68bfc-af1d-47c3-d02e-d7620e525e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization stops by reaching minimum gradient.\n",
            "Weights [[ 9.40884544]\n",
            " [-0.76023811]\n",
            " [-0.85193742]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "vBAqpEPrnNCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binaryRobustTest(theta, X_t, y_t, r_st):\n",
        "  n_row, _ = X_t.shape\n",
        "\n",
        "  # F : Features\n",
        "  F = np.concatenate((np.ones((n_row, 1)), X_t), axis=1) \n",
        "\n",
        "  # P : predictions \n",
        "  P = np.zeros((n_row, 1))\n",
        "  logloss = 0\n",
        "  prediction = np.zeros((n_row, 2))\n",
        "  for i in range(n_row):\n",
        "    W = r_st[i]\n",
        "    temp =  (np.dot(np.transpose(theta), np.transpose(F[i, :])) * y_t[i] * W)[0]      \n",
        "    temp_max = max(temp, -1 * temp)\n",
        "    temp_min = min(temp, -1 * temp)\n",
        "    P[i] = np.exp(temp - temp_max - np.log(1 + np.exp(temp_min - temp_max)))\n",
        "    logloss = logloss - np.log(P[i])\n",
        "\n",
        "    if y_t[i] == 1:\n",
        "      prediction[i] = [P[i], 1 - P[i]]\n",
        "    else:\n",
        "      prediction[i] = [1 - P[i], P[i]]\n",
        "\n",
        "  logloss = logloss / n_row / 0.6931\n",
        "  return logloss, prediction\n",
        "\n",
        "def computeAcc(pred, y):\n",
        "  n_row, n_class = pred.shape\n",
        "  \n",
        "  max_ind = np.argmax(pred, axis = 1)\n",
        "\n",
        "  summ = 0\n",
        "\n",
        "  if n_class == 2:\n",
        "    for i in range(n_row):\n",
        "      if max_ind[i] == 1 and y[i] == -1:\n",
        "        summ += 1\n",
        "      elif max_ind[i] == 0 and y[i] == 1:\n",
        "        summ += 1\n",
        "  else:\n",
        "    summ = sum(np.argmax(pred, axis = 1) == y_t - 1)\n",
        "\n",
        "  return summ / n_row"
      ],
      "metadata": {
        "id": "NBxGgX1tnNwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Robost \n",
        "d_s = mvn_s.pdf(x_2)\n",
        "d_t = mvn_t.pdf(x_2)"
      ],
      "metadata": {
        "id": "BgUO9mgnrF7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logloss_1, pred_1 = binaryRobustTest(theta_1, x_2, y_2, d_s / d_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkxdsV8hrWNa",
        "outputId": "9004ecff-c7af-4110-9e36-219964fac9f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.82562143] [[4.98721790e-01 5.01278210e-01]\n",
            " [3.75410707e-01 6.24589293e-01]\n",
            " [2.87288358e-01 7.12711642e-01]\n",
            " [4.92253351e-01 5.07746649e-01]\n",
            " [9.99926840e-01 7.31602132e-05]\n",
            " [2.58896032e-01 7.41103968e-01]\n",
            " [6.92374255e-01 3.07625745e-01]\n",
            " [1.19306263e-01 8.80693737e-01]\n",
            " [4.80252940e-01 5.19747060e-01]\n",
            " [9.14501821e-01 8.54981788e-02]\n",
            " [9.37599379e-01 6.24006210e-02]\n",
            " [5.63100285e-01 4.36899715e-01]\n",
            " [3.77913750e-01 6.22086250e-01]\n",
            " [4.44454276e-01 5.55545724e-01]\n",
            " [3.77350230e-02 9.62264977e-01]\n",
            " [5.35448942e-02 9.46455106e-01]\n",
            " [1.07016685e-01 8.92983315e-01]\n",
            " [4.99622400e-01 5.00377600e-01]\n",
            " [1.25002038e-01 8.74997962e-01]\n",
            " [1.42800777e-01 8.57199223e-01]\n",
            " [3.78958754e-01 6.21041246e-01]\n",
            " [4.30090664e-01 5.69909336e-01]\n",
            " [4.99999675e-01 5.00000325e-01]\n",
            " [4.16871304e-01 5.83128696e-01]\n",
            " [4.56561259e-01 5.43438741e-01]\n",
            " [3.39346405e-01 6.60653595e-01]\n",
            " [4.98707133e-01 5.01292867e-01]\n",
            " [3.58463613e-01 6.41536387e-01]\n",
            " [4.99982035e-01 5.00017965e-01]\n",
            " [1.93031286e-01 8.06968714e-01]\n",
            " [1.35690268e-01 8.64309732e-01]\n",
            " [2.77496374e-01 7.22503626e-01]\n",
            " [5.04773403e-02 9.49522660e-01]\n",
            " [4.99923573e-01 5.00076427e-01]\n",
            " [6.16795986e-01 3.83204014e-01]\n",
            " [4.99995631e-01 5.00004369e-01]\n",
            " [9.42816917e-01 5.71830828e-02]\n",
            " [2.31845469e-01 7.68154531e-01]\n",
            " [9.55765258e-01 4.42347421e-02]\n",
            " [1.01828867e-01 8.98171133e-01]\n",
            " [6.70819784e-02 9.32918022e-01]\n",
            " [2.24803676e-01 7.75196324e-01]\n",
            " [4.99997855e-01 5.00002145e-01]\n",
            " [5.85854185e-04 9.99414146e-01]\n",
            " [9.77093361e-01 2.29066386e-02]\n",
            " [8.04340639e-01 1.95659361e-01]\n",
            " [3.04350565e-01 6.95649435e-01]\n",
            " [5.42307140e-02 9.45769286e-01]\n",
            " [2.67433165e-02 9.73256683e-01]\n",
            " [4.97341318e-01 5.02658682e-01]\n",
            " [9.79388822e-01 2.06111777e-02]\n",
            " [3.05670753e-01 6.94329247e-01]\n",
            " [4.99996794e-01 5.00003206e-01]\n",
            " [2.03452400e-01 7.96547600e-01]\n",
            " [4.20191265e-03 9.95798087e-01]\n",
            " [3.90963986e-01 6.09036014e-01]\n",
            " [4.95125988e-01 5.04874012e-01]\n",
            " [4.74144749e-01 5.25855251e-01]\n",
            " [3.61911898e-01 6.38088102e-01]\n",
            " [4.84246059e-01 5.15753941e-01]\n",
            " [4.93252057e-01 5.06747943e-01]\n",
            " [8.95361707e-02 9.10463829e-01]\n",
            " [9.44327646e-01 5.56723541e-02]\n",
            " [9.54890953e-01 4.51090467e-02]\n",
            " [2.48977205e-01 7.51022795e-01]\n",
            " [4.96273960e-01 5.03726040e-01]\n",
            " [4.99898288e-01 5.00101712e-01]\n",
            " [4.94485645e-01 5.05514355e-01]\n",
            " [3.63468556e-01 6.36531444e-01]\n",
            " [3.92029185e-01 6.07970815e-01]\n",
            " [4.55197031e-01 5.44802969e-01]\n",
            " [9.28556864e-01 7.14431360e-02]\n",
            " [4.26872447e-01 5.73127553e-01]\n",
            " [4.99426871e-01 5.00573129e-01]\n",
            " [4.17787042e-03 9.95822130e-01]\n",
            " [1.08910840e-01 8.91089160e-01]\n",
            " [4.99747925e-01 5.00252075e-01]\n",
            " [2.65815094e-01 7.34184906e-01]\n",
            " [1.20473342e-01 8.79526658e-01]\n",
            " [4.43991350e-01 5.56008650e-01]\n",
            " [2.07761075e-01 7.92238925e-01]\n",
            " [4.99559187e-01 5.00440813e-01]\n",
            " [4.99992903e-01 5.00007097e-01]\n",
            " [1.35283934e-01 8.64716066e-01]\n",
            " [9.83381352e-01 1.66186478e-02]\n",
            " [1.22536939e-01 8.77463061e-01]\n",
            " [5.02737039e-01 4.97262961e-01]\n",
            " [8.97508710e-01 1.02491290e-01]\n",
            " [5.07850045e-01 4.92149955e-01]\n",
            " [4.16768363e-02 9.58323164e-01]\n",
            " [1.17818556e-01 8.82181444e-01]\n",
            " [4.99078754e-01 5.00921246e-01]\n",
            " [4.99999999e-01 5.00000001e-01]\n",
            " [1.40162854e-01 8.59837146e-01]\n",
            " [1.49582642e-01 8.50417358e-01]\n",
            " [1.17390287e-01 8.82609713e-01]\n",
            " [9.12425194e-01 8.75748059e-02]\n",
            " [3.48581552e-01 6.51418448e-01]\n",
            " [4.75561625e-01 5.24438375e-01]\n",
            " [9.08915998e-01 9.10840020e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logloss_2, pred_2 = binaryRobustTest(theta_2, x_2, y_2, np.ones((x_1.shape[0], 1)))\n",
        "print(logloss_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX5hh4G7ryiH",
        "outputId": "3fc08d85-2df2-4f6b-f881-156c82e778cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.78499119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logloss_3, pred_3 = binaryRobustTest(theta_3, x_2, y_2, np.ones((x_1.shape[0], 1)))\n",
        "print(logloss_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdvUgB8WtVR9",
        "outputId": "564cc8c6-532c-4b35-829d-067e51209fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.69593336]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What do these results mean? \n",
        "print(computeAcc(pred_1, y_2))\n",
        "print(computeAcc(pred_2, y_2))\n",
        "print(computeAcc(pred_3, y_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR7rPN4Htalw",
        "outputId": "d462147e-8e4b-46de-ab30-720faebf86c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.89\n",
            "0.9\n",
            "0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MultiClass Classification"
      ],
      "metadata": {
        "id": "3DfdxoUUwzw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "folder_path = '/content' # TODO Change this\n",
        "\n",
        "iris_train = scipy.io.loadmat(os.path.join(folder_path, 'iris_train.mat'))['iris_train']\n",
        "iris_test = scipy.io.loadmat(os.path.join(folder_path, 'iris_test.mat'))['iris_test']\n",
        "\n",
        "X_s = iris_train[:,0:-1]\n",
        "y_s = iris_train[:, -1]\n",
        "X_t = iris_test[:,0:-1]\n",
        "y_t = iris_test[:,-1]\n"
      ],
      "metadata": {
        "id": "f-x7il86yMPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n"
      ],
      "metadata": {
        "id": "7nVajMrByMqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LRDensityEstimation(X_s, X_t, lambdas = [0.0625, 1, 16]):\n",
        "\n",
        "  np.random.seed(10) # seed set in matlab code as well\n",
        "\n",
        "  ns_row, _ = X_s.shape\n",
        "  nt_row, _ = X_t.shape\n",
        "\n",
        "  inda_s = np.arange(ns_row)\n",
        "  inda_t = np.arange(nt_row)\n",
        "\n",
        "  nv_s = int(np.floor(0.2 * ns_row))\n",
        "  nv_t = int(np.floor(0.2 * nt_row))\n",
        "\n",
        "  indv_s = np.array([92, 3, 74, 87, 57, 26, 23, 85, 19, 10, 75, 103, 1, 54, 111, 64, 116, 30, 118, 71, 105, 14, 36]) - 1 # indv_s = np.random.permutation(ns_row)[:nv_s] # \n",
        "\n",
        "  indv_t = np.array([22, 14, 31, 18, 15, 29]) - 1 # np.random.permutation(nt_row)[:nv_t]\n",
        "\n",
        "  indt_s = np.setdiff1d(inda_s, indv_s)\n",
        "  \n",
        "  indt_t = np.setdiff1d(inda_t, indv_t)\n",
        "\n",
        "  X_train = np.concatenate((X_s[indt_s, :], X_t[indt_t, :]))\n",
        "  X_valid = np.concatenate((X_s[indv_s, :], X_t[indv_t, :]))\n",
        "  \n",
        "  y_train = np.concatenate((np.ones((ns_row - nv_s, 1)), -1 * np.ones((nt_row - nv_t, 1)) ))\n",
        "  y_valid = np.concatenate((np.ones((nv_s, 1)), -1 * np.ones((nv_t, 1)) ))\n",
        "\n",
        "  rt_st = np.ones((ns_row + nt_row - nv_s - nv_t, 1))\n",
        "  rv_st = np.ones((nv_s + nv_t, 1))\n",
        "  \n",
        "  logloss = np.zeros((len(lambdas), 1))\n",
        "  for i, lamb in enumerate(lambdas):\n",
        "    theta = binaryRobustTrain(X_train, y_train, rt_st, rt_st, lamb=lamb,min_gradient=0.1)\n",
        "    _, pred = binaryRobustTest(theta, X_valid, y_valid, rv_st )\n",
        "    logloss[i] = (-sum(np.log(pred[:nv_s, 0])) - sum(np.log(pred[nv_s: nv_s + nv_t, 1]))) / (nv_s + nv_t) / 0.6931\n",
        "\n",
        "  ind_min = np.argmin(logloss)\n",
        "\n",
        "  X_train = np.concatenate((X_s, X_t))\n",
        "  y_train = np.concatenate((np.ones((ns_row, 1)), -1 * np.ones((nt_row, 1)) ))\n",
        "  r_st = np.ones((ns_row + nt_row, 1))\n",
        "\n",
        "  theta = binaryRobustTrain(X_train, y_train, r_st, r_st, lambdas[ind_min])\n",
        "  _, pred = binaryRobustTest(theta, X_train, y_train, r_st)\n",
        "  print(pred)\n",
        "\n",
        "  d_ss = pred[:ns_row, 0]\n",
        "  d_st = pred[:ns_row, 1]\n",
        "\n",
        "  d_ts = pred[ns_row:, 0]\n",
        "  d_tt = pred[ns_row:, 1]\n",
        "\n",
        "  return d_ss, d_st, d_ts, d_tt\n",
        "\n",
        "d_ss, d_st, d_ts, d_tt = LRDensityEstimation(X_s, X_t, [0.1, 1, 10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoMSv73QmAIA",
        "outputId": "b4a44ef3-2f0a-47a0-c46e-dfbf7bc90fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization stops by reaching minimum gradient.\n",
            "Optimization stops by reaching minimum gradient.\n",
            "Optimization stops by reaching minimum gradient.\n",
            "Optimization stops by reaching minimum gradient.\n",
            "[[4.89220620e-01 5.10779380e-01]\n",
            " [7.71536817e-01 2.28463183e-01]\n",
            " [6.45858005e-01 3.54141995e-01]\n",
            " [7.95041119e-01 2.04958881e-01]\n",
            " [8.88689504e-01 1.11310496e-01]\n",
            " [7.48191866e-01 2.51808134e-01]\n",
            " [5.32154209e-01 4.67845791e-01]\n",
            " [7.93256883e-01 2.06743117e-01]\n",
            " [6.16145836e-01 3.83854164e-01]\n",
            " [5.87216006e-01 4.12783994e-01]\n",
            " [6.32044796e-01 3.67955204e-01]\n",
            " [5.89128479e-01 4.10871521e-01]\n",
            " [5.30824243e-01 4.69175757e-01]\n",
            " [4.96827171e-01 5.03172829e-01]\n",
            " [6.53010165e-01 3.46989835e-01]\n",
            " [6.40233768e-01 3.59766232e-01]\n",
            " [7.72793798e-01 2.27206202e-01]\n",
            " [6.13764757e-01 3.86235243e-01]\n",
            " [4.71216716e-01 5.28783284e-01]\n",
            " [6.84203432e-01 3.15796568e-01]\n",
            " [5.82563687e-01 4.17436313e-01]\n",
            " [6.14509614e-01 3.85490386e-01]\n",
            " [9.95133571e-01 4.86642948e-03]\n",
            " [9.90252858e-01 9.74714240e-03]\n",
            " [9.95120057e-01 4.87994327e-03]\n",
            " [8.77471423e-01 1.22528577e-01]\n",
            " [9.87519159e-01 1.24808413e-02]\n",
            " [9.48756918e-01 5.12430821e-02]\n",
            " [9.92049048e-01 7.95095199e-03]\n",
            " [9.86154840e-01 1.38451601e-02]\n",
            " [8.92971271e-01 1.07028729e-01]\n",
            " [9.74514377e-01 2.54856230e-02]\n",
            " [8.83053590e-01 1.16946410e-01]\n",
            " [9.78053007e-01 2.19469929e-02]\n",
            " [9.30868039e-01 6.91319609e-02]\n",
            " [9.91134146e-01 8.86585429e-03]\n",
            " [9.65647283e-01 3.43527166e-02]\n",
            " [9.09309348e-01 9.06906515e-02]\n",
            " [9.64784975e-01 3.52150246e-02]\n",
            " [8.73880416e-01 1.26119584e-01]\n",
            " [9.89645119e-01 1.03548806e-02]\n",
            " [9.64320383e-01 3.56796175e-02]\n",
            " [9.79874665e-01 2.01253349e-02]\n",
            " [9.66070615e-01 3.39293848e-02]\n",
            " [9.80173650e-01 1.98263502e-02]\n",
            " [9.88770616e-01 1.12293836e-02]\n",
            " [9.90685375e-01 9.31462545e-03]\n",
            " [9.95132445e-01 4.86755454e-03]\n",
            " [9.77473317e-01 2.25266832e-02]\n",
            " [8.66977073e-01 1.33022927e-01]\n",
            " [8.40907328e-01 1.59092672e-01]\n",
            " [8.11696501e-01 1.88303499e-01]\n",
            " [9.29893854e-01 7.01061455e-02]\n",
            " [9.80657790e-01 1.93422101e-02]\n",
            " [9.55509572e-01 4.44904277e-02]\n",
            " [9.88602437e-01 1.13975629e-02]\n",
            " [9.93203814e-01 6.79618589e-03]\n",
            " [9.59817232e-01 4.01827678e-02]\n",
            " [9.46051273e-01 5.39487265e-02]\n",
            " [8.98163313e-01 1.01836687e-01]\n",
            " [9.03542504e-01 9.64574963e-02]\n",
            " [9.79549193e-01 2.04508072e-02]\n",
            " [9.25042862e-01 7.49571380e-02]\n",
            " [9.29814602e-01 7.01853983e-02]\n",
            " [9.45778025e-01 5.42219748e-02]\n",
            " [9.49150627e-01 5.08493729e-02]\n",
            " [9.74208266e-01 2.57917336e-02]\n",
            " [7.26076611e-01 2.73923389e-01]\n",
            " [9.42163279e-01 5.78367213e-02]\n",
            " [9.98876078e-01 1.12392229e-03]\n",
            " [9.84820945e-01 1.51790549e-02]\n",
            " [9.98924928e-01 1.07507217e-03]\n",
            " [9.93579350e-01 6.42064992e-03]\n",
            " [9.97906382e-01 2.09361788e-03]\n",
            " [9.99561271e-01 4.38729306e-04]\n",
            " [9.98657072e-01 1.34292832e-03]\n",
            " [9.94661905e-01 5.33809478e-03]\n",
            " [9.99762568e-01 2.37431684e-04]\n",
            " [9.97003112e-01 2.99688818e-03]\n",
            " [9.93593356e-01 6.40664423e-03]\n",
            " [9.98171728e-01 1.82827155e-03]\n",
            " [9.81468956e-01 1.85310441e-02]\n",
            " [9.94154834e-01 5.84516624e-03]\n",
            " [9.98077819e-01 1.92218056e-03]\n",
            " [9.95427343e-01 4.57265671e-03]\n",
            " [9.99864012e-01 1.35987556e-04]\n",
            " [9.99625315e-01 3.74684940e-04]\n",
            " [9.60883441e-01 3.91165590e-02]\n",
            " [9.99136157e-01 8.63842984e-04]\n",
            " [9.83943383e-01 1.60566166e-02]\n",
            " [9.99456842e-01 5.43158170e-04]\n",
            " [9.90141198e-01 9.85880166e-03]\n",
            " [9.98563935e-01 1.43606472e-03]\n",
            " [9.98762464e-01 1.23753608e-03]\n",
            " [9.89512682e-01 1.04873177e-02]\n",
            " [9.90554797e-01 9.44520295e-03]\n",
            " [9.96271388e-01 3.72861206e-03]\n",
            " [9.97710814e-01 2.28918637e-03]\n",
            " [9.98830375e-01 1.16962504e-03]\n",
            " [9.99838704e-01 1.61296098e-04]\n",
            " [9.96858481e-01 3.14151887e-03]\n",
            " [9.86100096e-01 1.38999040e-02]\n",
            " [9.77523468e-01 2.24765317e-02]\n",
            " [9.99680865e-01 3.19134581e-04]\n",
            " [9.98633330e-01 1.36666976e-03]\n",
            " [9.95286712e-01 4.71328821e-03]\n",
            " [9.88861872e-01 1.11381281e-02]\n",
            " [9.98512640e-01 1.48735997e-03]\n",
            " [9.98909341e-01 1.09065862e-03]\n",
            " [9.98838741e-01 1.16125888e-03]\n",
            " [9.84820945e-01 1.51790549e-02]\n",
            " [9.99073056e-01 9.26943508e-04]\n",
            " [9.99277512e-01 7.22488170e-04]\n",
            " [9.98367169e-01 1.63283147e-03]\n",
            " [9.90098564e-01 9.90143650e-03]\n",
            " [9.96427470e-01 3.57252990e-03]\n",
            " [9.98021646e-01 1.97835377e-03]\n",
            " [9.88429059e-01 1.15709407e-02]\n",
            " [3.03016500e-01 6.96983500e-01]\n",
            " [2.83768591e-01 7.16231409e-01]\n",
            " [2.49636916e-01 7.50363084e-01]\n",
            " [4.81619059e-01 5.18380941e-01]\n",
            " [3.43392315e-01 6.56607685e-01]\n",
            " [4.37864364e-01 5.62135636e-01]\n",
            " [1.66591085e-01 8.33408915e-01]\n",
            " [2.95514834e-01 7.04485166e-01]\n",
            " [3.80606094e-01 6.19393906e-01]\n",
            " [2.42418296e-01 7.57581704e-01]\n",
            " [1.29166710e-01 8.70833290e-01]\n",
            " [3.23033047e-01 6.76966953e-01]\n",
            " [4.03485381e-01 5.96514619e-01]\n",
            " [3.46515237e-01 6.53484763e-01]\n",
            " [5.31460361e-01 4.68539639e-01]\n",
            " [3.03680752e-01 6.96319248e-01]\n",
            " [3.10154191e-01 6.89845809e-01]\n",
            " [2.95514834e-01 7.04485166e-01]\n",
            " [3.64907136e-01 6.35092864e-01]\n",
            " [2.95514834e-01 7.04485166e-01]\n",
            " [1.76848646e-01 8.23151354e-01]\n",
            " [4.90555336e-01 5.09444664e-01]\n",
            " [1.23430420e-01 8.76569580e-01]\n",
            " [2.09231421e-01 7.90768579e-01]\n",
            " [6.39682452e-01 3.60317548e-01]\n",
            " [3.10961272e-01 6.89038728e-01]\n",
            " [2.63391833e-01 7.36608167e-01]\n",
            " [4.04685650e-01 5.95314350e-01]\n",
            " [6.28459510e-01 3.71540490e-01]\n",
            " [5.76307407e-01 4.23692593e-01]\n",
            " [6.35537277e-01 3.64462723e-01]\n",
            " [9.01786826e-01 9.82131743e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "def multiClassRobustTrain(X_s, y_s, n_class, r_st, r_ts, lamb = 0.1, lr = 0.01, max_itr = 100000, min_gradient = 0.001):\n",
        "  n_row, n_col = X_s.shape\n",
        "\n",
        "  # lamb : regularization matrix (3 x 4) \n",
        "  lamb = lamb.reshape(-1, 1)  \n",
        "  lamb = np.transpose(np.tile(lamb, n_class))\n",
        "  \n",
        "  # F : features \n",
        "  F = X_s \n",
        "\n",
        "  # F_g : features reweighted to match source / target distribution \n",
        "  F_g = F * np.tile(r_ts, n_col)\n",
        "\n",
        "  # Y : binarized matrix representing labels\n",
        "  Y = lb.fit_transform(y_s)\n",
        "\n",
        "  # P : predictions \n",
        "  P = np.zeros((n_row, n_class)) \n",
        "\n",
        "  # S_g : \n",
        "  S_g = np.ones((n_class, n_col)) * 1e-8\n",
        "\n",
        "  t = 1\n",
        "\n",
        "  # theta : weights matrix\n",
        "  theta = np.ones((n_class, n_col)) # not randomly assigned? \n",
        "\n",
        "  # l_0 : ______ \n",
        "  l_0 = 0\n",
        "\n",
        "  # l_1 : \n",
        "  l_1 = (1 + (1 + (4 * l_0 ** 2)) ** 0.5) / 2\n",
        "  delta_1 = 0\n",
        "\n",
        "  while True:\n",
        "    t = t + 1\n",
        "    decay = np.sqrt(1000 / (1000 + t))\n",
        "    l_2 = (1 + (1 + (4 * l_1 ** 2)) ** 0.5) / 2\n",
        "    l_3 = (1 - l_1) / l_2\n",
        "\n",
        "    for i in range(n_row):\n",
        "      W = r_st[i]\n",
        "      temp =  np.dot(theta, np.transpose(F[i, :])) * W\n",
        "      temp = temp - np.max(temp)\n",
        "      sum_temp = sum(np.exp(temp))\n",
        "      P[i] = np.exp(temp - np.log(sum_temp))\n",
        "\n",
        "    G = np.dot(np.transpose(P) - np.transpose(Y), F_g) + 2 * lamb * theta\n",
        "\n",
        "    if np.linalg.norm(G) < min_gradient:\n",
        "      print('Optimization stops by reaching minimum gradient.')\n",
        "      break\n",
        "    elif t > max_itr:\n",
        "      print(\"Optimizination stops by reaching maximum iteration\")\n",
        "      break\n",
        "\n",
        "    S_g = S_g + G ** 2\n",
        "    delta_2 = theta - decay * lr * G / np.sqrt(S_g) \n",
        "    theta = np.dot((1 - l_3), delta_2) + np.dot(l_3, delta_1)\n",
        "    delta_1 = delta_2\n",
        "    l_1 = l_2\n",
        "    \n",
        "  return theta"
      ],
      "metadata": {
        "id": "2V9JCYprw13_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This density estimation algorithm isn't described in the paper right? \\\n",
        "Question: No bias? \\\n",
        "Question: What is d_ss and d_st? Isn't d_ss just 1 - d_st? \n"
      ],
      "metadata": {
        "id": "Ze1Z4quaj-Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust learning\n",
        "\n",
        "ns_row, n_col = X_s.shape\n",
        "\n",
        "n_class = int(max(y_s))\n",
        "\n",
        "lamb = 2 * np.std(X_s, axis=0, ddof=1) / np.sqrt(ns_row)\n",
        "lamb[0] = 1\n",
        "\n",
        "theta_robust = multiClassRobustTrain(X_s, y_s, n_class, d_ss / d_st, np.ones((ns_row, 1)), lamb=lamb, lr = 1, min_gradient=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzyBcLk7j_de",
        "outputId": "31be91a6-020c-4d99-b811-880214a46707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization stops by reaching minimum gradient.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta_lr = multiClassRobustTrain(X_s, y_s, n_class, np.ones((ns_row, 1)), np.ones((ns_row, 1)), lamb=lamb, lr = 1, min_gradient=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foUaf_XL3i9r",
        "outputId": "df6511cb-5238-46ab-a915-d1e40703fe7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization stops by reaching minimum gradient.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_ts = np.reshape(d_st / d_ss, (-1, 1))\n",
        "theta_iw = multiClassRobustTrain(X_s, y_s, n_class, np.ones((ns_row, 1)), r_ts, lamb=lamb, lr = 1, min_gradient=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5xA84O74TEc",
        "outputId": "fbdccfb6-3557-4d8b-edc7-bd5c9b04c1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization stops by reaching minimum gradient.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "pVpXrZe13nsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiClassRobustTest(theta, X_t, y_t, n_class, r_st):\n",
        "  n_row, _ = X_t.shape\n",
        "  F = X_t \n",
        "  P = np.zeros((n_row, n_class))\n",
        "  logloss = 0 \n",
        "\n",
        "  for i in range(n_row):\n",
        "      W = r_st[i]\n",
        "      temp =  np.dot(theta, np.transpose(F[i, :])) * W\n",
        "      temp = temp - np.max(temp)\n",
        "      sum_temp = sum(np.exp(temp))\n",
        "      P[i] = np.exp(temp - np.log(sum_temp))\n",
        "      logloss -= np.log(P[i, int(y_t[i]) - 1])\n",
        "\n",
        "  logloss = logloss / n_row / 0.6931\n",
        "  return logloss, P"
      ],
      "metadata": {
        "id": "pOode0kzyT4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logloss, pred = multiClassRobustTest(theta_robust, X_t, y_t, n_class, d_ts / d_tt)\n",
        "acc = computeAcc(pred, y_t)\n",
        "print(f'Acc is {acc} and logloss is {logloss} for robust method')"
      ],
      "metadata": {
        "id": "YEbPTr78l5X7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd4a608-3dbe-4520-8004-91ded58d0b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc is 1.0 and logloss is 0.4989368812192846 for robust method\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logloss, pred = multiClassRobustTest(theta_lr, X_t, y_t, n_class, np.ones((ns_row, 1)))\n",
        "acc = computeAcc(pred, y_t)\n",
        "print(f'Acc is {acc} and logloss is {logloss} for LR method')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iQzBZdqLszd",
        "outputId": "d2a1cdaf-eee9-4ad9-f9fd-10e0f34517dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc is 1.0 and logloss is 0.09988054970933052 for IR method\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logloss, pred = multiClassRobustTest(theta_iw, X_t, y_t, n_class, np.ones((ns_row, 1)))\n",
        "acc = computeAcc(pred, y_t)\n",
        "print(f'Acc is {acc} and logloss is {logloss} for IW method')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGbDeVYl24-Y",
        "outputId": "625a54ef-559c-4e39-da5d-f76f1c8dd368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc is 0.96875 and logloss is 0.17910794400844812 for IW method\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isn't there a data leakage problem? \n",
        "Thinking that in a healthcare setting, you may not know the target distribution as data is coming in one after another. \n"
      ],
      "metadata": {
        "id": "VuU5SohvSe09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gbHlWbz65b4s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}